# Waze User Churn Prediction

## Introduction

Waze, as a popular navigation app, has embarked on a crucial mission to leverage machine learning models to predict user churn. The ability to identify users at high risk of churning holds immense strategic importance for Waze. If Waze can proactively engage this segment of users with tailored offers and interventions, there is a significant opportunity to retain them and foster continued user loyalty.

User churn, or the loss of users, is a common challenge faced by many tech platforms. Without insights into the reasons behind user churn, Waze risks losing a valuable user base without a clear understanding of why it's happening. This project aims to address this challenge by developing and testing machine learning models, specifically random forest and XGBoost, to predict user churn accurately.

The outcome of this predictive modeling endeavor is not just about numbers and algorithms; it's about empowering Waze's leadership with actionable insights. With a successful model in place, Waze can make informed business decisions to prevent user churn, enhance user retention strategies, and ultimately contribute to the continued growth and success of the platform.

In the journey ahead, we will explore the intricacies of the random forest and XGBoost models, evaluate their performance on Waze's user data, and provide a comprehensive executive summary. The goal is to equip Waze's leadership with the tools they need to navigate the challenges of user churn and steer the company toward sustainable growth.

## Part 1: Plan and Data Exploration

### Project Overview
- Aim: Predict user churn for Waze.
- Dataset: Contains user activity and churn labels.

### Data Exploration
- Explored dataset characteristics, features, and target variable.
- Checked for missing values and conducted basic statistical analyses.

### Feature Engineering
- Engineered new features to enhance model performance.

## Part 2: Model Building (Logistic Regression)

### Logistic Regression
1. Instantiated and trained a logistic regression model.
2. Evaluated model performance on training data.
3. Utilized cross-validation for robust evaluation.
4. Discussed insights from logistic regression results.

## Part 3: Model Building (Random Forest and XGBoost)

### Random Forest
1. Tuned hyperparameters for a random forest classifier.
2. Examined the best score and hyperparameter combination.
3. Evaluated model performance on training and validation data.

### XGBoost
1. Tuned hyperparameters for an XGBoost classifier.
2. Examined the best score and hyperparameter combination.
3. Evaluated model performance on training and validation data.

## Part 4: Model Evaluation and Optimization

### Model Performance on Validation and Test Data
- Evaluated random forest and XGBoost models on validation data.
- Reflected on the Execute stage in the PACE (Plan, Analyze, Construct, Execute) framework.

### Tasks Completed
- Champion model prediction on test data.
- Confusion matrix analysis.
- Feature importance examination.
- Precision-recall curve exploration.
- Identified an optimal decision threshold.

### Next Steps
- Write an executive summary based on model findings.
- Present insights and recommendations to stakeholders.

---

**Note:** The information presented in this README.md file is based on a fictional scenario created for practical purposes.
